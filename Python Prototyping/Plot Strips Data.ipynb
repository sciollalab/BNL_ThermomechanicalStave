{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn on autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>%autoreload</b>: Reload all modules (except those excluded by %aimport) automatically now.<br>\n",
    "<b>%autoreload 0</b>: Disable automatic reloading.<br>\n",
    "<b>%autoreload 1</b>: Reload all modules imported with %aimport every time before executing the Python code typed.<br>\n",
    "<b>%autoreload 2</b>: Reload all modules (except those excluded by %aimport) every time before executing the Python code typed.</p>\n",
    "<p><b>%aimport</b>: List modules which are to be automatically imported or not to be imported.<br>\n",
    "<b>%aimport foo</b>: Import module ‘foo’ and mark it to be autoreloaded for %autoreload 1<br>\n",
    "<b>%aimport -foo</b>: Mark module ‘foo’ to not be autoreloaded.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show plots in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#import imreg_dft as ird\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load additional definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import process_strips as p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set plot formatting defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('classic')\n",
    "plt.rcParams['figure.figsize'] = (15.0, 10.0)\n",
    "plt.rcParams['axes.titlesize'] = 28\n",
    "plt.rcParams['axes.labelsize'] = 24\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.rcParams['legend.fontsize'] = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calc_theta(opp, opp_err, adj, adj_err):\n",
    "    theta = np.tanh(opp/adj)  # sin(opp) / cos(adj)\n",
    "    d_opp = (np.cos(opp)/np.cos(adj))\n",
    "    d_adj = (-np.sin(opp)/np.sin(adj))\n",
    "    theta_err = np.sqrt((d_opp * opp_err)**2 + (d_adj * adj_err)**2)\n",
    "    \n",
    "    return theta, theta_err\n",
    "\n",
    "def plot_strips(x, means, devs, save_dir, file_num):\n",
    "    \n",
    "    # Get the dimensions of the 2D array\n",
    "    l, w = np.shape(means)\n",
    "    \n",
    "    thetas = []\n",
    "    chi = []\n",
    "    strip_loc = []\n",
    "    strip_num = []\n",
    "    lines = []\n",
    "\n",
    "    # Iterate the columns\n",
    "    for i in range(0, w-1):\n",
    "        \n",
    "        # Grab that column value from each row\n",
    "        yy = np.array([row[i] for row in means], dtype=float)\n",
    "        ss = np.array([row[i] for row in devs], dtype=float)\n",
    "        xx = x\n",
    "        \n",
    "        # Remove any zeroes, as they are the result of failed fits\n",
    "        z = np.where(yy > 0.0)[0]\n",
    "        \n",
    "        yy = yy[z]\n",
    "        ss = ss[z]\n",
    "        xx = xx[z]\n",
    "\n",
    "        # Make sure the data isn't empty\n",
    "        if (len(yy) > 1 and len(ss) > 1):\n",
    "\n",
    "            # Fix anything that might be an invalid value\n",
    "            yy = p.fix_broken_values(yy, 0.0)\n",
    "            ss = p.fix_broken_values(ss, 0.0001)\n",
    "\n",
    "            # Look for outliers\n",
    "            o = p.detect_outliers(xx, yy, ss, 1, 20.0, 15.0)\n",
    "\n",
    "            # Cull outliers\n",
    "            yy = yy[o]\n",
    "            xx = xx[o]\n",
    "            ss = ss[o]\n",
    "\n",
    "            # Make sure the data isn't empty\n",
    "            if (len(yy) > 1 and len(ss) > 1):\n",
    "                ss = ss # * 1.525\n",
    "\n",
    "                # Unsquare sigma\n",
    "                sqrt_s = np.sqrt(ss)\n",
    "\n",
    "                # Fit a line\n",
    "                popt, pcov = np.polyfit(xx, yy, 1, w=1.0/sqrt_s, cov=True)\n",
    "                poly = np.poly1d(popt)\n",
    "                lines.append([popt, np.diag(pcov)])\n",
    "\n",
    "                # Chi squared\n",
    "                cs = p.calc_chisquare(poly(xx), yy, ss, len(yy)-2)\n",
    "                chi.append(cs)\n",
    "\n",
    "                strip_loc.append([popt[1], np.sqrt(np.diag(pcov)[1])])\n",
    "\n",
    "                plt.errorbar(xx, yy, yerr=sqrt_s, fmt='ko', ecolor='k', alpha=0.10, zorder=1)\n",
    "                plt.plot(x, poly(x), 'b--', lw=3, label=\"Fit Line: %s\" % poly, zorder=2)\n",
    "                plt.title(\"Strip %d, $\\chi^2$ = %f\" % (i, cs))\n",
    "                plt.xlabel(\"X Location [pixels]\")\n",
    "                plt.ylabel(\"Y Location [pixels]\")\n",
    "                plt.legend(loc='best')\n",
    "                plt.ticklabel_format(useOffset=False)\n",
    "                plt.savefig(\"%s/%d_strip_%d.png\" % (save_dir, file_num, i), dpi=300)\n",
    "                plt.show()\n",
    "                \n",
    "    return strip_num, strip_loc, chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "def make_array(my_list):\n",
    "    return [np.array(row) for row in my_list]\n",
    "\n",
    "def get_column(my_array, col):\n",
    "    return np.array([np.array(row)[col] for row in my_array])\n",
    "\n",
    "def get_critical_points(p, left, right):\n",
    "    bounds = [left, right]\n",
    "    crit_points = bounds + [x for x in p.deriv().r if x.imag == 0 and bounds[0] < x.real < bounds[1]]\n",
    "    return crit_points\n",
    "\n",
    "def visualize_curvature(x, means, devs, save_dir, file_num):\n",
    "    strip_num, strip_loc, chi = plot_strips(x, means, devs, save_dir, file_num)\n",
    "\n",
    "    strips = get_column(strip_loc, 0)\n",
    "    fit, covb = np.polyfit(strips, chi, 2, cov=True)\n",
    "    poly = np.poly1d(fit)\n",
    "    crit = get_critical_points(poly, strips[0], strips[-1])\n",
    "    min_chi = np.min(crit)\n",
    "\n",
    "    plt.plot(strips, chi, 'bo', lw=3)\n",
    "    plt.plot(strips, np.polyval(fit, strips), 'g--', lw=2, label=\"Minimum: %1.3f\" % min_chi)\n",
    "    plt.title(\"Evolution of $\\chi^2$\")\n",
    "    plt.xlabel(\"Strip Location [Pixels]\")\n",
    "    plt.ylabel(\"$\\chi^2/D.O.F.$\")\n",
    "    plt.legend(loc='best')\n",
    "    #plt.savefig(\"%s/chi_squared.png\" % (save_dir), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Configuration variables\n",
    "rect = [3000, 3000]\n",
    "step = 1\n",
    "\n",
    "img_dir = r'D:\\Documents\\School\\Brookhaven\\Images\\2017-06-15\\Fast Conversion Test'\n",
    "load_dir = r'%s\\%dx%d\\Step %d' % (img_dir, rect[0], rect[1], step)\n",
    "save_dir = r'%s\\Results' % (load_dir)\n",
    "\n",
    "match_pattern = \"^([0-9]*)_results.csv$\"\n",
    "\n",
    "# Make the save directory, if it does not exist\n",
    "make_dir(save_dir)\n",
    "\n",
    "# Get list of files in the image directory\n",
    "filenames = next(os.walk(load_dir))[2]\n",
    "\n",
    "dist = []\n",
    "\n",
    "# Iterate all the files\n",
    "for fn in filenames:\n",
    "    # Regex match on the filenames\n",
    "    match = re.search(match_pattern, fn)\n",
    "\n",
    "    # Pattern matched\n",
    "    if match:\n",
    "        # Get the file number\n",
    "        try:\n",
    "            file_num = int(match.group(1))\n",
    "        except:\n",
    "            file_num = 1\n",
    "\n",
    "        load_file = r'%s\\%d_results.csv' % (load_dir, file_num) \n",
    "        print(\"Loading results from %s...\" % (fn))\n",
    "\n",
    "        x, means, devs, dx = p.load_results(load_file, header=True)\n",
    "        dist.append(np.array(dx))\n",
    "        \n",
    "        visualize_curvature(x, means, devs, save_dir, file_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gauss(x, a, mu, sigma):\n",
    "    return a * np.exp(-(x - mu)**2.0 / (2 * sigma**2))\n",
    "\n",
    "def get_x(bins):\n",
    "    x = np.linspace(0, len(bins)-2, len(bins)-1)\n",
    "    offset_x = bins[0]\n",
    "    delta_x = np.gradient(bins)[0]\n",
    "    return x, delta_x, offset_x\n",
    "\n",
    "def get_numbins(data):\n",
    "    # Freedman-Diaconis\n",
    "    IQR = np.subtract(*np.percentile(data, [75, 25]))\n",
    "    h = (2 * IQR / (len(data)**(1/3)))\n",
    "    numbins = int((np.nanmax(data) - np.nanmin(data)) / h)\n",
    "    return numbins\n",
    "\n",
    "def trim_n_stddev(data, mean, std, n):\n",
    "    data_trim = data.copy()\n",
    "    data_trim = data_trim[data_trim <= mean + n*std]\n",
    "    data_trim = data_trim[data_trim >= mean - n*std]\n",
    "    return data_trim\n",
    "    \n",
    "def fit_nonlinear(x, n):\n",
    "    from scipy.optimize import curve_fit\n",
    "    \n",
    "    amp = max(n)\n",
    "    mean = np.mean(pitches)\n",
    "    std = np.std(pitches)\n",
    "\n",
    "    # Fit the histogram\n",
    "    fit, fit_covb = curve_fit(gauss, x, n, p0=[amp, mean, std])\n",
    "\n",
    "    return fit, fit_covb\n",
    "\n",
    "    \n",
    "pitches = []\n",
    "\n",
    "for i in range(len(dist)):\n",
    "    for j in range(len(dist[i])):\n",
    "        for k in range(len(dist[i][j])):\n",
    "            if (dist[i][j][k] is not None):\n",
    "                pitches.append(dist[i][j][k])\n",
    "        \n",
    "pitches = np.array(pitches)\n",
    "\n",
    "# Rough chop to remove impossible values\n",
    "pitches = pitches[pitches > 44.0]\n",
    "pitches = pitches[pitches < 50.0]\n",
    "\n",
    "# Get mean and std of the pitches\n",
    "mean = np.mode(pitches)\n",
    "std = np.std(pitches)\n",
    "\n",
    "# Trim out everything more than 3 standard deviations from the mean\n",
    "pitches_trim = trim_n_stddev(pitches, mean, np.sqrt(std), 3.0)\n",
    "\n",
    "# Put the trimmed data into a histogram\n",
    "n, bins, patches = plt.hist(pitches_trim, bins='auto')\n",
    "plt.close()\n",
    "\n",
    "# Number of samples\n",
    "N = len(pitches_trim)\n",
    "\n",
    "# Get mean and std of the trimmed pitches\n",
    "mean = np.mean(pitches_trim)\n",
    "std = np.std(pitches_trim)\n",
    "\n",
    "# Arbitrary cutoff of counts per bin\n",
    "# This is to cull empty bins that happen due to the 1/4 integral nature of the data\n",
    "locs = np.where(n > 0)\n",
    "bins = bins[locs]\n",
    "n = n[locs]\n",
    "\n",
    "# Calculate a drawing width for the bins\n",
    "bin_width = (bins[1] - bins[0])\n",
    "\n",
    "# Un-normalize the fit\n",
    "# FIXME: This is really hacky\n",
    "amp = n[n == n.max()]\n",
    "\n",
    "# Error is sqrt(std)/sqrt(N)\n",
    "sqrt_std = np.sqrt(std/N)\n",
    "\n",
    "# Create a smoother set of input values for the gaussian plot\n",
    "x = np.linspace(bins[0], bins[-1], 1000)\n",
    "\n",
    "# Plot the histogram with the gaussian fit\n",
    "plt.bar(bins, n, facecolor='green', alpha=0.75, width=bin_width, align='center', label=\"N = %d\" % N)\n",
    "plt.plot(x, gauss(x, amp, mean, std), 'b--', lw=3, label=\"Mean = %2.3f, Sigma = %2.3f\" % (mean, sqrt_std))\n",
    "plt.title(\"Distribution of Strip Pitches\")\n",
    "plt.xlabel(\"Pitch [Pixels]\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"%s/pitches.png\" % (save_dir), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel to Micron Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(filename, results, header=None):\n",
    "    import csv\n",
    "    with open(filename, \"a\", newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        if (header):\n",
    "            writer.writerow(header)\n",
    "        for line in results:\n",
    "            writer.writerow(line)\n",
    "\n",
    "def pixels_to_microns(microns, microns_err, pixels, pixels_err):\n",
    "    factor = microns / pixels\n",
    "    factor_err = np.sqrt(((-microns/pixels**2)*pixels_err)**2)\n",
    "    \n",
    "    return factor, factor_err\n",
    "\n",
    "microns = 74.5\n",
    "factor, factor_err = pixels_to_microns(microns, 0.0, mean, sqrt_std)\n",
    "\n",
    "results = []\n",
    "results.append([mean, sqrt_std, microns, 0.0, factor, factor_err])\n",
    "\n",
    "save_results(\"%s/pixel_to_micron.csv\" % (save_dir), results, ['Mean Strip Pitch [px]', 'Mean Strip Pitch Err [px]', 'Strip Pitch [um]', 'Strip Pitch Err [um]', 'Conversion [px/um]', 'Conversion Err [px/um]'])\n",
    "\n",
    "print(\"Mean strip pitch: %1.3f pixels, pm %0.3f\" %(mean, sqrt_std))\n",
    "print(\"Conversion factor: %1.5f microns per pixel, pm %0.5f\" %(factor, factor_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
